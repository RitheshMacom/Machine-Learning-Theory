{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c437861",
   "metadata": {},
   "source": [
    "### Q1. What are the key tasks that machine learning entails? What does data Pre-Processing imply ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe2e19",
   "metadata": {},
   "source": [
    "    The machine learning key tasks involve are…\n",
    "\n",
    "        Data Mining\n",
    "        Data cleaning\n",
    "        Data preprocessing\n",
    "        Making Assumptions about data\n",
    "        Choosing model\n",
    "        Model Tuning\n",
    "        Testing the model for final deployment in the production\n",
    "        Deploy the model into the productions.\n",
    "        \n",
    "    Data Preprocessing is a very vital step in machine learning tasks, data preprocessing involves many tasks like data cleaning, data transforming if needed, feature engineering, dimensionality reduction if needed. Those steps are put a vital effect on the model.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7e610",
   "metadata": {},
   "source": [
    "### Q2. Describe quantitative and qualitative data in depth. Make a distinction between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f1da6",
   "metadata": {},
   "source": [
    "    Quantitative data – those are in numerical or numeric format are called quantitative data, these can be both integer or float format, any continuous numerical data can be called quantitative data. We need quantitative data for creating a machine learning model because the machine learning model can’t work with any other type of data.\n",
    "\n",
    "    Qualitative data – those are represented through English words or English letters are called qualitative data. We need special care for this type of data. We need to convert them into numerical form so we can use these qualitative data in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcbaf1",
   "metadata": {},
   "source": [
    "### Q4. What are the various causes of machine learning data issues? What are the ramifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd5612",
   "metadata": {},
   "source": [
    "    The data is coming from the real world can be very messy and unstructured we can not use that data directly for building the model, we need some preprocessing, that data can come in various format and various shape, for creating the model the most used format is a tabular format, we need to convert them in tabular format, the data can be a different type, it can be mixes of quantitative and qualitative, we need to convert every type of data into a numerical format to use in a machine learning model. \n",
    "    \n",
    "    Also in some cases may be all the data section is not filled with data, these are called missing data, this is one major problem in datasets, we also have a different technique to remove them or replace them appropriate value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff2dc5",
   "metadata": {},
   "source": [
    "### Q5. Demonstrate various approaches to categorical data exploration with appropriate examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67eae7",
   "metadata": {},
   "source": [
    "    There are various approaches to explore categorical data we can explore data with visualize approach or\n",
    "\n",
    "    we can sort the data based on their class or labels means converting all categorical values in tabular form by calculating aggregating values like group-by, or value_counts – a function which is available on python language.\n",
    "\n",
    "    And there is a more appropriate way to visualize the data to observe better, we can plot the data using python plotting libraries like matplotlib or seaborn to observe more details from our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e87846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is some exaple of exploring categorial data\n",
    "cat_list = ['Dog', 'Cat', 'Dog', 'Dog', 'Cat', 'Tiger', 'Rat', 'Cat', 'Tiger']\n",
    "#in above i have created a list of smoe animal names and we can pot this list using bar graph to observe the \n",
    "# occuring of animal names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b07334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a1035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cat_list);\n",
    "plt.title('Animal names');\n",
    "plt.xlabel('Animal');\n",
    "plt.ylabel('Occurance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d43630",
   "metadata": {},
   "source": [
    "    From abobe bar graph we can observe the categorial value very eaily, that graph willl help us to identify of occurence of every element in our data set. here we can see 'Dog' appear 3 times from y axis label and 'Rat' is appear only 1 times in our list.\n",
    "\n",
    "    And other function that help us to find categorial entry from the dataframe for that we need to create pandas data frame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c5e571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animals</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Rajhasthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rat</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tiger</td>\n",
       "      <td>Rajhasthan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animals        City\n",
       "0     Dog     Kolkata\n",
       "1     Cat       Delhi\n",
       "2     Dog       Nepal\n",
       "3     Dog  Rajhasthan\n",
       "4   Tiger     Kolkata\n",
       "5     Rat       Delhi\n",
       "6     Cat       Nepal\n",
       "7   Tiger  Rajhasthan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creatig panda simple dataframe from dictionary\n",
    "df_dict = {\n",
    "    'Animals': ['Dog', 'Cat', 'Dog', 'Dog', 'Tiger', 'Rat', 'Cat', 'Tiger'],\n",
    "    'City': ['Kolkata', 'Delhi', 'Nepal', 'Rajhasthan', 'Kolkata', 'Delhi', 'Nepal', 'Rajhasthan']\n",
    "}\n",
    "#importing pandas dataframe\n",
    "from pandas import DataFrame\n",
    "df = DataFrame(df_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab32fcc6",
   "metadata": {},
   "source": [
    "    Here we create a simple datafram with two columns consisting categorial value and we can use some function to explore categorial value occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988312ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog      3\n",
       "Cat      2\n",
       "Tiger    2\n",
       "Rat      1\n",
       "Name: Animals, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking of appearance of animal and city name form our dataframe\n",
    "df['Animals'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0407f5",
   "metadata": {},
   "source": [
    "    Here we can observe the which animal appear in how many of times in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870439b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rajhasthan    2\n",
       "Delhi         2\n",
       "Kolkata       2\n",
       "Nepal         2\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['City'].value_counts()\n",
    "# checking the city name form our dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968123be",
   "metadata": {},
   "source": [
    "### 6. How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab1e9a",
   "metadata": {},
   "source": [
    "    The machine learning algorithms required a complete dataset with purity, which means we can’t pass it incomplete data with some NaN value in some columns if we do so our model will not be useful when we will using it on production.\n",
    "\n",
    "    The NaN value basically will bias our machine learning algorithm which have missing the value for that feature and replace the python NaN object which indicates the absence of data. This will impact on the model, the model will not perform well as expected just for the missing value.\n",
    "\n",
    "    As missing value is a common problem we have serval option to deal with it,\n",
    "\n",
    "    If the values are Numerical in data type, then we can convert the missing value by the mean of the full dataset or we can replace the missing value mode of the data. Or just can replace the missing value with zero that will not impact our model.\n",
    "    \n",
    "    If the values are Categorical in data types we can replace the missing value with the most frequent value occurring in the dataset.\n",
    "    \n",
    "    We also have one more approach the is also used in practices which is drop the rows that have missing value. But it can reduce our data size, we have to observe on that side, the rule of thumb says that if we are dropping 5% from our total data then we are fine.\n",
    "    \n",
    "    Which method we use in which case completely depends on the problem in hand and the dataset we have. The data scientist or machine learning engineer will decide which method to use in which case based on his experience, there is no hard code rule on that.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10552aed",
   "metadata": {},
   "source": [
    "### 7. Describe the various methods for dealing with missing data values in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308608c",
   "metadata": {},
   "source": [
    "    The missing value is one of the common problems that we encounter at the first step of the data preprocessing. The data can come from different sources, most of the data are not created by hand, almost every cases these data can be filled by a user of any product for any company, or survey report, or some daily trends, as we don’t have any control on creating the data set. We collect them from a different database or we can download from the various website as per our problem required. So the missing value comes with it, the missing values are nothing but the absence of data. Like if the data is about some survey report then some users may not give some answers to the survey and can skip a couple of questions in that case those unfilled answers will become a missing value in our dataset. We have some approach to deal with it...\n",
    "\n",
    "    Here I will create a simple dataset with both numerical and categorical value with some missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb977926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ram</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Kolaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodu</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Bhutan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modu</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Rajhasthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tim</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kine</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lofi</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kofi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   Age        City\n",
       "0   Ram  18.0      Kolaka\n",
       "1   Sam  20.0         NaN\n",
       "2  Jodu  44.0      Bhutan\n",
       "3  Modu  35.0  Rajhasthan\n",
       "4   Tim   NaN         NaN\n",
       "5  Kine  44.0     Kolkata\n",
       "6  Lofi  22.0         NaN\n",
       "7  Kofi   NaN     Kolkata"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first i will create a dataset to work with\n",
    "# imporing nan form numpy library\n",
    "from numpy import nan\n",
    "my_dict = {\n",
    "    'Name':['Ram', 'Sam', 'Jodu', 'Modu', 'Tim', 'Kine', 'Lofi', 'Kofi'],\n",
    "    'Age':[18, 20, 44, 35, nan, 44, 22, nan],\n",
    "    'City':['Kolaka', nan, 'Bhutan', 'Rajhasthan', nan, 'Kolkata', nan, 'Kolkata'],\n",
    "    \n",
    "            }\n",
    "\n",
    "df = DataFrame(my_dict) # creating dataframe\n",
    "df #showing the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97a838",
   "metadata": {},
   "source": [
    "    We can find the nan value by using isnull function and sum fuction followed by it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffec394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name    0\n",
       "Age     2\n",
       "City    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing values\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082cbff2",
   "metadata": {},
   "source": [
    "    from this we can see that the 'Age' column have the 2 nan value and city have 3 nan value froom our dataframe.\n",
    "\n",
    "    The 'Age' column have numerical value in it and 'City' have categorical value, so we have to use different aproch for both of them\n",
    "\n",
    "    We can use fillna function for filling the nan value in our datafarme, and we can pass the value we want to use the fill nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deaec694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating mean age from our dataframe\n",
    "df['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd1369",
   "metadata": {},
   "source": [
    "    We can see the mean age from all our user is 30 we can assume that the missing age value can be 30 as it is our mean user age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae80f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ram</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Kolaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodu</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Bhutan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modu</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Rajhasthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tim</td>\n",
       "      <td>30.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kine</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lofi</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kofi</td>\n",
       "      <td>30.5</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   Age        City\n",
       "0   Ram  18.0      Kolaka\n",
       "1   Sam  20.0         NaN\n",
       "2  Jodu  44.0      Bhutan\n",
       "3  Modu  35.0  Rajhasthan\n",
       "4   Tim  30.5         NaN\n",
       "5  Kine  44.0     Kolkata\n",
       "6  Lofi  22.0         NaN\n",
       "7  Kofi  30.5     Kolkata"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling nan value with mean age 30\n",
    "df['Age'].fillna(value=30.5, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b24c0d",
   "metadata": {},
   "source": [
    "    Now we can see that from previous dataset where 'Tim' and 'Kofi' did not put there age we replace those nan with 30 on index 4 and 7. but the city column still have their nan value.\n",
    "\n",
    "    Although the Machine learning libray scikit learn have one function to handle missing value which is Simpleimputer from this we do not have to calculate mean value separately. the function have parameter called strategy which take mean, median and most_frequent to handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c33c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kolkata       2\n",
       "Rajhasthan    1\n",
       "Kolaka        1\n",
       "Bhutan        1\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for most frequent city name from the dataset\n",
    "df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23cc3e0",
   "metadata": {},
   "source": [
    "    We can see the kolkata is most frequent city so we can assume that most of user from kolkata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954753eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ram</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Kolaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jodu</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Bhutan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Modu</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Rajhasthan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tim</td>\n",
       "      <td>30.5</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kine</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lofi</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kofi</td>\n",
       "      <td>30.5</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   Age        City\n",
       "0   Ram  18.0      Kolaka\n",
       "1   Sam  20.0     Kolkata\n",
       "2  Jodu  44.0      Bhutan\n",
       "3  Modu  35.0  Rajhasthan\n",
       "4   Tim  30.5     Kolkata\n",
       "5  Kine  44.0     Kolkata\n",
       "6  Lofi  22.0     Kolkata\n",
       "7  Kofi  30.5     Kolkata"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling nan value in city column with kolkata\n",
    "df['City'].fillna(value='Kolkata', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218f4e2",
   "metadata": {},
   "source": [
    "    Now We have a complete clean data to work with.\n",
    "\n",
    "    It is also have to remember that Which method we use in which case completely depends on the problem in hand and the dataset we have. The data scientist or machine learning engineer will decide which method to use in which case based on his experience, there is no hard code rule on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56a0be",
   "metadata": {},
   "source": [
    "### 8. What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fea12",
   "metadata": {},
   "source": [
    "     The data preprocessing technique is the most vital and time-consuming approach in the data science domain. This step required lots of labor to prepare a good and clean dataset that we can feed into machine learning algorithms. The data preprocessing consists of serval steps …\n",
    "\n",
    "    Data Cleaning means we need to clean our data as per requirement, data come from source can not be used directly for model creation, these data will consist of unnecessary element and can be unstructured we need to perform various data cleaning for making them structured.\n",
    "    \n",
    "    Data transforming or data scaling also need to be done before train with those data in our model, if one feature data range does not match or the range differs too much then we need to perform data scaling to scale all numerical value a single and small range.\n",
    "    \n",
    "    Feature engineering needs to be done if that is needed if we have many features and we feel that all the features are not necessary for the model creation, we can check that from every feature weight. Removing unnecessary features or adding a new feature is called feature engineering.\n",
    "    \n",
    "    \n",
    "    Many Machine learning problems consist of lots of features even thousands of features, that can make the model very slow and very complex to handle. This problem is also referred to as the Curse of Dimensionality. Dimensionality reduction is also can be needed if we have lots of features or our data set consists of many columns then we have to reduce columns number without losing any information, in that time dimensionality reduction can be handy. PCA is the most common use approach for dimensionality reduction. There are also other function that can help to reduce the dimensions of our data set, like, Non-negative matrix factorization (NMF), Graph-based kernel PCA, Linear discriminant analysis (LDA).\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc6ae8",
   "metadata": {},
   "source": [
    "### 9.i. What is the IQR? What criteria are used to assess it?\n",
    "### ii. Describe the various components of a box plot in detail? When will the lower whisker surpass the upper whisker in length? How can box plots be used to identify outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd566d",
   "metadata": {},
   "source": [
    "    1. IQR or Inter-Quartile Range is a measure of dispersion. It is formulated as (third quartile-1st quartile). It is dependent on only 50% of the data. First quartile and third quartile are required to assess Inter Quartile Range.\n",
    "\n",
    "    2. boxplot gives us the 5 point summary which includes first quartile(median of the first 50% of the data), third quartile(median for second 50% of the data), median or 2nd quartile(exact mid point of the entire data), maximum value and minimum value. It also has two whiskers which provide us with a visual position of minimum and maximum value, below and above which lies the threshold beyond which any data point will be shown as an outlier. Outliers are declared by using formula Q1-(1.5 IQR) and Q3+(1.5 IQR). Lower whisker surpasses the upper whisker if the data is right skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e56897",
   "metadata": {},
   "source": [
    "### 10. Make brief notes on any two of the following:\n",
    "### i. Data collected at regular intervals\n",
    "### iii. Use a cross-tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2e721",
   "metadata": {},
   "source": [
    "    1.Data collection can be in many different forms. One of the probabilistic sampling techniques used in Statistics is Stratified sampling in which data is collected at regular intervals but with a random start. It is used for its simplicity.\n",
    "\n",
    "    2.ross tabs or cross tabulation are only used to find relations between two categorical variables where one categorical variable value would be giving row data and the other variable would give column data. Several tests like the chi square test can help find relations based on the cross tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d22c67",
   "metadata": {},
   "source": [
    "### 11. Make a comparison between:\n",
    "### ii. Histogram and box plot\n",
    "### iii. The average and median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5a2bf",
   "metadata": {},
   "source": [
    "    1.Histograms are data visualizations used for continous quantitative data. Box Plots are data visualizations used for describing any quantitative data. Histograms are used for checking the distribution type. Box Plots are used for describing data in 5 point summary and detecting outliers in data. Granularity can be changed using bins in Histograms. Box Plots do no feature any control over granularity.\n",
    "\n",
    "    2.Average is a measure of numerical centrality of a distribution. Median is a measure of positional centrality of a distribution. Average can also be referred to as the value that is closest to most number of values in a data. Median can also be referred to as the value which is exactly in the middle of a distribution. Averages are affected by presence of outliers. Medians are not affected by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84655c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
